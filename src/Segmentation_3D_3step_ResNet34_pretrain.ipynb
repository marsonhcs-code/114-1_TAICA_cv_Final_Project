{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0afd131b-84e8-47e7-ac53-c196411170bd",
   "metadata": {},
   "source": [
    "# Training pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b2dc4",
   "metadata": {},
   "source": [
    "### 0. import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9ea4f",
   "metadata": {},
   "source": [
    "### 1. Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78887324",
   "metadata": {},
   "source": [
    "##### path & format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b76e1f-94d6-4077-bf8f-3597c8fa503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. åŸºæœ¬åƒæ•¸è¨­å®š\n",
    "NUM_CLASSES_DETAILED = 12 # Detailed (12é¡): 0:BG, 1:SA, 2:RF, 3:VL, 4:VI, 5:VM, 6:AM, 7:GR, 8:BFL, 9:ST, 10:SM, 11:BFS\n",
    "NUM_CLASSES_ROUGH = 5 # Rough (5é¡): 0:BG, 1:SA, 2:QF, 3:GR, 4:HS\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True\n",
    "\n",
    "# 2. è³‡æ–™è·¯å¾‘\n",
    "PROJECT_ROOT = \"/home/n26141826/114-1_TAICA_cv_Final_Project\"\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, \"data\", \"npy_2D_dataset_with_Embedding\")\n",
    "TRAIN_DATA_DIR = os.path.join(DATA_DIR, \"train\") \n",
    "TEST_DATA_DIR = os.path.join(DATA_DIR, \"test\")\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(PROJECT_ROOT, \"checkpoints_ResNet34_pretrain\")\n",
    "RESULTS_DIR = os.path.join(PROJECT_ROOT, \"results_ResNet34_pretrain\")\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# 3. æ¨¡å‹å­˜æª”è·¯å¾‘ (Model Checkpoints)\n",
    "ROUGH_MODEL_PATH  = os.path.join(CHECKPOINT_DIR, \"rough_model_best.pth\")\n",
    "WARMUP_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"warmup_model.pth\")\n",
    "DETAIL_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"detail_model_best.pth\")\n",
    "EVAL_MODEL_PATH   = DETAIL_MODEL_PATH\n",
    "\n",
    "# 4. train loss / val loss ç´€éŒ„è·¯å¾‘\n",
    "ROUGH_LOSS_LOG  = os.path.join(RESULTS_DIR, \"rough_loss.csv\")\n",
    "ROUGH_LOSS_IMG   = os.path.join(RESULTS_DIR, \"rough_loss.png\")\n",
    "WARMUP_LOSS_LOG = os.path.join(RESULTS_DIR, \"warmup_loss.csv\")\n",
    "WARMUP_LOSS_IMG  = os.path.join(RESULTS_DIR, \"warmup_loss.png\")\n",
    "DETAIL_LOSS_LOG = os.path.join(RESULTS_DIR, \"detail_loss.csv\")\n",
    "DETAIL_LOSS_IMG  = os.path.join(RESULTS_DIR, \"detail_loss.png\")\n",
    "\n",
    "\n",
    "# 5. è©•ä¼°è¼¸å‡ºè·¯å¾‘\n",
    "EVAL_CSV_OUTPUT = os.path.join(RESULTS_DIR, \"evaluation_metrics_per_sequence.csv\")\n",
    "FLATTENED_METRICS_OUTPUT = os.path.join(RESULTS_DIR, \"flattened_metrics.csv\")\n",
    "\n",
    "# æ¨¡å‹æ¶æ§‹åƒæ•¸ (Model Architecture)\n",
    "IN_CHANNELS = 1        # è¼¸å…¥å½±åƒé€šé“æ•¸ (ç°éš)\n",
    "EMBEDDING_DIM = 64     # æ¢ä»¶å‘é‡ (Type/Pos) çš„ç¶­åº¦\n",
    "NUM_MRI_TYPES = 5      # MRI åºåˆ—ç¸½æ•¸ (Water, Fat, T1, T2, STIR)\n",
    "\n",
    "# è¦–è¦ºåŒ–è¨­å®š\n",
    "VIZ_INTERVAL = 50\n",
    "\n",
    "print(f\"âœ… Configuration Loaded!\")\n",
    "print(f\"   - Device     : {DEVICE}\")\n",
    "print(f\"   - Data       : {DATA_DIR}\")\n",
    "print(f\"   - Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"   - Results    : {RESULTS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aee6fef",
   "metadata": {},
   "source": [
    "#### Training Hyper-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ee370",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_SIZE = 512\n",
    "# å¹¾ä½•è®Šæ› (Joint Transform: Image + Label)\n",
    "AUG_P_FLIP = 0.5          # å·¦å³ç¿»è½‰çš„æ©Ÿç‡\n",
    "AUG_P_SCALE = 0.5         # éš¨æ©Ÿç¸®æ”¾çš„æ©Ÿç‡\n",
    "AUG_LIMIT_SCALE = 0.1     # ç¸®æ”¾å¹…åº¦ (0.1 ä»£è¡¨ 0.9x ~ 1.1x)\n",
    "\n",
    "# åƒç´ è®Šæ› (Independent Transform: Image Only)\n",
    "AUG_P_BRIGHTNESS = 0.5    # äº®åº¦/å°æ¯”åº¦èª¿æ•´æ©Ÿç‡\n",
    "AUG_LIMIT_BRIGHT = 0.2    # äº®åº¦èª¿æ•´å¹…åº¦ (+-20%)\n",
    "AUG_LIMIT_CONTRAST = 0.2  # å°æ¯”åº¦èª¿æ•´å¹…åº¦ (+-20%)\n",
    "\n",
    "# Pre-train (Rough)\n",
    "ROUGH_BATCH_SIZE = 32\n",
    "ROUGH_LR = 1e-3\n",
    "ROUGH_EPOCHS = 30\n",
    "\n",
    "# Hierarchical Warm-up (Detail Head Warm-up)\n",
    "WARMUP_BATCH_SIZE = 32    # ä½¿ç”¨ Detail Dataï¼Œé€šå¸¸é‡è¼ƒå°‘æˆ–éœ€è¼ƒå° Batch\n",
    "WARMUP_LR = 1e-3          # åªè¨“ç·´ Headï¼Œå¯ä»¥ç”¨å¤§ä¸€é»çš„ LR\n",
    "WARMUP_EPOCHS = 10        # çŸ­æš«ç†±èº«å³å¯\n",
    "# æ§åˆ¶ Student(Detail) æ¨¡ä»¿ Teacher(Rough) çš„å¼·åº¦\n",
    "# å»ºè­°ç¯„åœ: 0.1 ~ 1.0\n",
    "CONSISTENCY_WEIGHT = 0.5\n",
    "\n",
    "# Fine-tune (Detail)\n",
    "DETAIL_BATCH_SIZE = 24\n",
    "DETAIL_EPOCHS = 50\n",
    "DETAIL_LR_ENCODER = 1e-5 # Encoder æ…¢æ…¢ä¿® (å¾®æ•´å½¢)\n",
    "DETAIL_LR_DECODER = 1e-4 # Decoder æ­£å¸¸å­¸\n",
    "\n",
    "# Mappings & Definitions\n",
    "ROUGH_MAP = [0, 1, 2, 2, 2, 2, 0, 3, 4, 4, 4, 4]  # 0:BG, 1:SA, 2:QF, 3:GR, 4:HS\n",
    "# MRI åºåˆ—æ˜ å°„è¡¨ (Modality Mapping)\n",
    "TYPE_MAP = {\n",
    "    'Water': 0,\n",
    "    'FATFRACTION': 1, # é€šå¸¸å°‡ Fat Fraction è¦–ç‚º Fat é¡åˆ¥ï¼Œæˆ–ä¾ä½ éœ€æ±‚æ”¹ç‚ºç¨ç«‹ ID\n",
    "    'Fat': 1,\n",
    "    'T1': 2,\n",
    "    'T2': 3,\n",
    "    'STIR': 4\n",
    "}\n",
    "ID_TO_TYPE = {v: k for k, v in TYPE_MAP.items()}\n",
    "\n",
    "# å®šç¾©æ˜ å°„çŸ©é™£ (12é¡ -> 5é¡)\n",
    "# 0:BG, 1:SA, 2:RF, 3:VL, 4:VI, 5:VM, 6:AM, 7:GR, 8:BFL, 9:ST, 10:SM, 11:BFS\n",
    "# Map to: 0:BG, 1:SA, 2:QF, 3:GR, 4:HS\n",
    "MAPPING_MATRIX = torch.tensor([\n",
    "    [1, 0, 0, 0, 0], # 0->0\n",
    "    [0, 1, 0, 0, 0], # 1->1\n",
    "    [0, 0, 1, 0, 0], # 2->2\n",
    "    [0, 0, 1, 0, 0], # 3->2\n",
    "    [0, 0, 1, 0, 0], # 4->2\n",
    "    [0, 0, 1, 0, 0], # 5->2\n",
    "    [1, 0, 0, 0, 0], # 6->0 (AM -> BG)\n",
    "    [0, 0, 0, 1, 0], # 7->3\n",
    "    [0, 0, 0, 0, 1], # 8->4\n",
    "    [0, 0, 0, 0, 1], # 9->4\n",
    "    [0, 0, 0, 0, 1], # 10->4\n",
    "    [0, 0, 0, 0, 1]  # 11->4\n",
    "], dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "# Evaluation Configuration\n",
    "EVAL_BATCH_SIZE = 1\n",
    "# 2. è‚Œè‚‰åç¨±å°ç…§è¡¨ (1-11)\n",
    "MUSCLE_NAMES = {\n",
    "    1: 'Sartorius',\n",
    "    2: 'Rectus Femoris',\n",
    "    3: 'Vastus Lateralis',\n",
    "    4: 'Vastus Intermedius',\n",
    "    5: 'Vastus Medialis',\n",
    "    6: 'Adductor Magnus',\n",
    "    7: 'Gracilis',\n",
    "    8: 'Biceps Femoris LH',\n",
    "    9: 'Semitendinosus',\n",
    "    10: 'Semimembranosus',\n",
    "    11: 'Biceps Femoris SH'\n",
    "}\n",
    "# 3. è¦–è¦ºåŒ–é¡è‰²è¨­å®š (Visualization Colors)\n",
    "VIZ_COLORS = [\n",
    "    '#000000', '#e6194b', '#006400', '#228B22', '#32CD32', '#7CFC00', \n",
    "    '#911eb4', '#46f0f0', '#00008B', '#0000CD', '#4169E1', '#87CEEB'\n",
    "]\n",
    "VIZ_CMAP = mcolors.ListedColormap(VIZ_COLORS)\n",
    "VIZ_NORM = mcolors.BoundaryNorm(boundaries=np.arange(13)-0.5, ncolors=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860711f1",
   "metadata": {},
   "source": [
    "### 2. Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metrics (ç‚ºäº†è·Ÿçµ„å“¡æ¯”å°ï¼Œä½¿ç”¨æ¨™æº– Dice) ---\n",
    "def dice_score(preds, targets, num_classes):\n",
    "    # ç°¡å–®çš„ Dice è¨ˆç®—ç¯„ä¾‹ï¼Œçµ„å“¡å¯èƒ½æœ‰æ›´è¤‡é›œçš„ç‰ˆæœ¬ï¼Œå¯æ›¿æ›\n",
    "    dice_list = []\n",
    "    preds = torch.argmax(preds, dim=1)\n",
    "    \n",
    "    for cls in range(1, num_classes): # Skip background\n",
    "        pred_cls = (preds == cls).float()\n",
    "        target_cls = (targets == cls).float()\n",
    "        \n",
    "        intersection = (pred_cls * target_cls).sum()\n",
    "        union = pred_cls.sum() + target_cls.sum()\n",
    "        \n",
    "        score = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "        dice_list.append(score.item())\n",
    "        \n",
    "    return np.mean(dice_list)\n",
    "\n",
    "def plot_training_curves(log_path, image_path=None):\n",
    "    \"\"\"\n",
    "    è®€å– CSV Log ä¸¦ç•«å‡º Loss å’Œ Dice æ›²ç·šï¼Œ\n",
    "    ä½¿ç”¨ clear_output é”æˆå³æ™‚åˆ·æ–°æ•ˆæœã€‚\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_path):\n",
    "        return\n",
    "\n",
    "    # è®€å–æ•¸æ“š\n",
    "    try:\n",
    "        df = pd.read_csv(log_path)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        return\n",
    "\n",
    "    # è¨­å®šç•«å¸ƒ (å·¦é‚Š Loss, å³é‚Š Dice)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # --- 1. Loss Curve ---\n",
    "    ax1.plot(df['epoch'], df['train_loss'], label='Train Loss', marker='o', color='tab:blue')\n",
    "    ax1.plot(df['epoch'], df['val_loss'], label='Val Loss', marker='o', color='tab:orange')\n",
    "    ax1.set_title(\"Loss Curve\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "    ax1.legend()\n",
    "\n",
    "    # --- 2. Dice Curve ---\n",
    "    if 'val_dice' in df.columns:\n",
    "        ax2.plot(df['epoch'], df['val_dice'], label='Val Dice', marker='o', color='tab:green')\n",
    "        ax2.set_title(\"Validation Dice Score\")\n",
    "        ax2.set_xlabel(\"Epoch\")\n",
    "        ax2.set_ylabel(\"Dice\")\n",
    "        ax2.grid(True, linestyle='--', alpha=0.6)\n",
    "        ax2.legend()\n",
    "        \n",
    "        # æ¨™å‡ºç›®å‰çš„æœ€é«˜åˆ†\n",
    "        max_dice = df['val_dice'].max()\n",
    "        max_epoch = df.loc[df['val_dice'].idxmax(), 'epoch']\n",
    "        ax2.annotate(f'Max: {max_dice:.4f}', xy=(max_epoch, max_dice), \n",
    "                     xytext=(max_epoch, max_dice - 0.05),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if image_path:\n",
    "        plt.savefig(image_path)\n",
    "    \n",
    "    # æ¸…é™¤ä¸Šä¸€æ¬¡çš„åœ–ä¸¦é¡¯ç¤ºæ–°çš„\n",
    "    clear_output(wait=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152bf0d-d38c-4fd7-ae71-f5aed52dbade",
   "metadata": {},
   "source": [
    "### 2. Train - validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86931b30-eab1-4171-9e1f-d44bb311b1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. æœå°‹æ‰€æœ‰ .npy æª”æ¡ˆ\n",
    "all_files = glob.glob(os.path.join(TRAIN_DATA_DIR, \"*.npy\"))\n",
    "print(f\"Total .npy files found in train data: {len(all_files)}\")\n",
    "\n",
    "# 2. ä¾ç…§ Subject åˆ†é¡\n",
    "train_files = []\n",
    "val_files = []\n",
    "train_detail = []\n",
    "train_without_detail = []\n",
    "for i in all_files:\n",
    "    data = np.load(i, allow_pickle=True).item()\n",
    "    if data.get('has_detail'):\n",
    "        train_detail.append(i)\n",
    "    else:\n",
    "        train_without_detail.append(i)\n",
    "# --- split rough only training data & val ---\n",
    "train_roughonly_subs, val_roughonly_subs = train_test_split(\n",
    "    train_without_detail, test_size=0.1, random_state=42\n",
    ")\n",
    "# --- split detail training data & val ---\n",
    "train_detail_subs, val_detail_subs = train_test_split(\n",
    "    train_detail, test_size=0.1, random_state=42\n",
    ")\n",
    "# --- combine ---\n",
    "train_files = train_roughonly_subs + train_detail_subs\n",
    "val_files = val_roughonly_subs + val_detail_subs\n",
    "# --- è¨ˆç®— Train åˆ†ä½ˆ ---\n",
    "train_rough_seq_distribution = {}\n",
    "for i in train_files:\n",
    "    data = np.load(i, allow_pickle=True).item()\n",
    "    key = data.get('type_idx')\n",
    "    if key not in train_rough_seq_distribution:\n",
    "        train_rough_seq_distribution[key] = 0\n",
    "    train_rough_seq_distribution[key] += 1\n",
    "# --- è¨ˆç®— Val åˆ†ä½ˆ ---\n",
    "val_rough_seq_distribution = {}\n",
    "for i in val_files:\n",
    "    data = np.load(i, allow_pickle=True).item()\n",
    "    key = data.get('type_idx')\n",
    "    if key not in val_rough_seq_distribution:\n",
    "        val_rough_seq_distribution[key] = 0\n",
    "    val_rough_seq_distribution[key] += 1\n",
    "# --- log ---\n",
    "print(\"-\"*30)\n",
    "print(f\"Train Files : {len(train_files)}\")\n",
    "print(f\"Val Files   : {len(val_files)}\")\n",
    "print(\"-\"*30)\n",
    "\n",
    "# --- measure type distribution ---\n",
    "# 1. æ‰¾å‡ºæ‰€æœ‰å‡ºç¾éçš„é¡åˆ¥ ID (å–è¯é›†ä¸¦æ’åº)\n",
    "all_keys = sorted(set(train_rough_seq_distribution.keys()) | set(val_rough_seq_distribution.keys()))\n",
    "\n",
    "# 2. æº–å‚™è³‡æ–™å­—å…¸\n",
    "data = {}\n",
    "for k in all_keys:\n",
    "    # å–å¾—é¡åˆ¥åç¨±\n",
    "    seq_name = ID_TO_TYPE.get(k, f\"Unknown({k})\")\n",
    "    \n",
    "    # å–å¾— Train å’Œ Val çš„æ•¸é‡\n",
    "    train_count = train_rough_seq_distribution.get(k, 0)\n",
    "    val_count = val_rough_seq_distribution.get(k, 0)\n",
    "    \n",
    "    # è¨ˆç®—æ¯”ç‡ (Val / Train)\n",
    "    ratio = val_count / train_count if train_count > 0 else 0.0\n",
    "    \n",
    "    # å­˜å…¥å­—å…¸\n",
    "    data[seq_name] = [train_count, val_count, ratio]\n",
    "\n",
    "# 3. è½‰æˆ DataFrame\n",
    "df_dist = pd.DataFrame.from_dict(data, orient='index', columns=['Train', 'Val', 'Val : Train'])\n",
    "\n",
    "# 4. åŠ å…¥ Total ç¸½å’Œåˆ—\n",
    "total_train = df_dist['Train'].sum()\n",
    "total_val = df_dist['Val'].sum()\n",
    "total_ratio = total_val / total_train if total_train > 0 else 0.0\n",
    "\n",
    "df_dist.loc['Total'] = [total_train, total_val, total_ratio]\n",
    "\n",
    "# 5. æ ¼å¼åŒ–é¡¯ç¤º (é¡¯ç¤ºç™¾åˆ†æ¯”å¯èƒ½æœƒæ›´ç›´è§€)\n",
    "styled_df = df_dist.style.format({\n",
    "    'Train': '{:,.0f}',       # æ•´æ•¸\n",
    "    'Val': '{:,.0f}',         # æ•´æ•¸\n",
    "    'Val : Train': '{:.1%}'   # è½‰æˆç™¾åˆ†æ¯” (ä¾‹å¦‚ 0.11 -> 11.0%)\n",
    "})\n",
    "display(styled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc2f1e6-c234-4c09-a893-7d8793bbd73a",
   "metadata": {},
   "source": [
    "### 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e05d4d-ea47-42f3-adb9-a23c2d9228eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceMasterDataset(Dataset):\n",
    "    def __init__(self, file_list, mode='rough', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_list (list): List of .npy file paths\n",
    "            mode (str): 'rough' or 'detail'\n",
    "            transform: Albumentations transform\n",
    "        \"\"\"\n",
    "        self.file_list = file_list\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        # Rough Map (12 -> 5)\n",
    "        self.rough_map = np.array(ROUGH_MAP, dtype=np.uint8)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 1. Load Dictionary\n",
    "        data = np.load(self.file_list[idx], allow_pickle=True).item()\n",
    "        \n",
    "        image = data['image'] # (H, W) float32\n",
    "        z_pos = data['z_pos']\n",
    "        type_idx = data['type_idx']\n",
    "\n",
    "        # 2. Select Label\n",
    "        if self.mode == 'rough':\n",
    "            label = data['rough_label']\n",
    "        elif self.mode == 'detail':\n",
    "            label = data['detail_label']\n",
    "            # å¦‚æœæ˜¯ Detail æ¨¡å¼ä½†æ²’æœ‰æ¨™è¨»ï¼Œé€™å¼µåœ–æ‡‰è©²è¢«éæ¿¾æˆ– Loss Masking\n",
    "            # é€™è£¡ç°¡å–®è™•ç†ï¼šå¦‚æœå…¨é»‘å‰‡è¦–ç‚ºèƒŒæ™¯\n",
    "        \n",
    "        # 3. Augmentation\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image, mask=label)\n",
    "            image = augmented['image']\n",
    "            label = augmented['mask']\n",
    "        \n",
    "        # 4. To Tensor\n",
    "        if isinstance(image, np.ndarray):\n",
    "            if image.ndim == 2: \n",
    "                image = image[np.newaxis, ...] # (1, H, W)\n",
    "            image = image.copy()\n",
    "            \n",
    "        if isinstance(label, np.ndarray):\n",
    "            label = label.copy()\n",
    "\n",
    "        return (\n",
    "            torch.from_numpy(image).float(),\n",
    "            torch.from_numpy(label).long(),\n",
    "            torch.tensor(z_pos).float(),\n",
    "            torch.tensor(type_idx).long()\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1342f483",
   "metadata": {},
   "source": [
    "### 3. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfcca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    # 1. Independent Transform (åªæ”¹ Image ä¸å½±éŸ¿åº§æ¨™)\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=AUG_LIMIT_BRIGHT,  # äº®åº¦\n",
    "        contrast_limit=AUG_LIMIT_CONTRAST,  # å°æ¯”åº¦\n",
    "        p=AUG_P_BRIGHTNESS\n",
    "    ),\n",
    "    # (å¯é¸) é«˜æ–¯é›œè¨Š\n",
    "    # A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "\n",
    "    # 2. Joint Transform (Image èˆ‡ Label åŒæ­¥)\n",
    "    A.HorizontalFlip(p=AUG_P_FLIP),   # å·¦å³ç¿»è½‰ (Horizontal Flip)\n",
    "    A.RandomScale(scale_limit=AUG_LIMIT_SCALE, p=AUG_P_SCALE), # éš¨æ©Ÿç¸®æ”¾ (Zoom In/Out)\n",
    "    \n",
    "    # 3. Resize\n",
    "    A.Resize(height=TARGET_SIZE, width=TARGET_SIZE, interpolation=1),\n",
    "])\n",
    "\n",
    "# é©—è­‰é›†ï¼šåªåš Resizeï¼Œä¸åšä»»ä½•éš¨æ©Ÿå¢å¼·\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=TARGET_SIZE, width=TARGET_SIZE, interpolation=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94897917-c99f-40ac-ac7e-045376189e99",
   "metadata": {},
   "source": [
    "### 4. Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973e752",
   "metadata": {},
   "source": [
    "#### main model (Conditioned U-Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfea000-86e9-43bc-9059-745b36e31a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ConditionedResNetUNet(nn.Module):\n",
    "    def __init__(self, n_channels=1, n_classes_rough=5, n_classes_detail=12, embed_dim=64, num_mri_types=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ==========================================\n",
    "        # 1. Encoder (Pre-trained ResNet34)\n",
    "        # ==========================================\n",
    "        # è¼‰å…¥ ImageNet é è¨“ç·´æ¬Šé‡\n",
    "        resnet = models.resnet34(weights=models.ResNet34_Weights.DEFAULT)\n",
    "        \n",
    "        # [ä¿®æ”¹ç¬¬ä¸€å±¤] ResNet é è¨­åƒ RGB (3 channel)ï¼Œæˆ‘å€‘æ˜¯ç°éš (1 channel)\n",
    "        # ç­–ç•¥ï¼šå°‡åŸæœ¬ 3 channel çš„æ¬Šé‡å–å¹³å‡ï¼Œæ¿ƒç¸®æˆ 1 channel\n",
    "        original_conv1 = resnet.conv1\n",
    "        self.enc_conv1 = nn.Conv2d(n_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        with torch.no_grad():\n",
    "            self.enc_conv1.weight[:] = original_conv1.weight.sum(dim=1, keepdim=True)\n",
    "            \n",
    "        self.enc_bn1 = resnet.bn1\n",
    "        self.enc_relu = resnet.relu\n",
    "        self.enc_maxpool = resnet.maxpool\n",
    "        \n",
    "        self.enc_layer1 = resnet.layer1 # 64\n",
    "        self.enc_layer2 = resnet.layer2 # 128\n",
    "        self.enc_layer3 = resnet.layer3 # 256\n",
    "        self.enc_layer4 = resnet.layer4 # 512 (Bottleneck)\n",
    "        \n",
    "        # ==========================================\n",
    "        # 2. Embedding Layers (ä¸è®Š)\n",
    "        # ==========================================\n",
    "        self.type_emb = nn.Embedding(num_embeddings=num_mri_types, embedding_dim=embed_dim)\n",
    "        self.pos_emb = nn.Sequential(\n",
    "            nn.Linear(1, embed_dim), nn.ReLU(), nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "        \n",
    "        # ==========================================\n",
    "        # 3. Fusion Layer\n",
    "        # ==========================================\n",
    "        # ResNet34 Bottleneck è¼¸å‡ºæ˜¯ 512 channels\n",
    "        # æˆ‘å€‘è¦èåˆ: 512 (Feature) + 64 (Type) + 64 (Pos) = 640 -> è½‰å› 512\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Conv2d(512 + embed_dim*2, 512, kernel_size=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # ==========================================\n",
    "        # 4. Decoder (é…åˆ ResNet é€šé“æ•¸èª¿æ•´)\n",
    "        # ==========================================\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        # ResNet34 Skip Connections:\n",
    "        # Layer4: 512\n",
    "        # Layer3: 256\n",
    "        # Layer2: 128\n",
    "        # Layer1: 64\n",
    "        # Conv1 : 64\n",
    "        \n",
    "        # Up1: Fusion(512) + Layer3(256) -> 256\n",
    "        self.up1 = self._block(512 + 256, 256)\n",
    "        # Up2: Up1(256) + Layer2(128) -> 128\n",
    "        self.up2 = self._block(256 + 128, 128)\n",
    "        # Up3: Up2(128) + Layer1(64) -> 64\n",
    "        self.up3 = self._block(128 + 64, 64)\n",
    "        # Up4: Up3(64) + Conv1(64) -> 64 (Original ResNet Conv1 output size is same as Layer1, but MaxPool happened)\n",
    "        # Note: ResNet structure is: Conv1(1/2) -> MaxPool(1/4) -> Layer1(1/4). \n",
    "        # æ‰€ä»¥ Layer1 å’Œ MaxPool å¾Œçš„ Feature Map å¤§å°ä¸€æ¨£ã€‚\n",
    "        # ç‚ºäº†ç°¡åŒ–ï¼Œæœ€å¾Œä¸€å±¤æˆ‘å€‘ç›´æ¥å¾ 64 -> 32ï¼Œå† Upsample å›åŸåœ–\n",
    "        self.up4 = self._block(64, 32) \n",
    "        \n",
    "        self.final_up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True) # å›åˆ°åŸåœ–å¤§å° (å¦‚æœéœ€è¦)\n",
    "        # è¨»: ResNet Conv1 æ˜¯ stride 2ï¼Œæ‰€ä»¥æœ€å¾Œ Feature map æ˜¯åŸåœ– 1/2ã€‚\n",
    "        # ä¸Šé¢ up4 å‡ºä¾†å¾Œé‚„æ˜¯ 1/2 å¤§å°ï¼Œéœ€è¦å† up ä¸€æ¬¡ã€‚\n",
    "        \n",
    "        # ==========================================\n",
    "        # 5. Dual Heads\n",
    "        # ==========================================\n",
    "        self.head_rough = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), # è£œå›æœ€å¾Œçš„ 2x\n",
    "            nn.Conv2d(32, n_classes_rough, kernel_size=1)\n",
    "        )\n",
    "        self.head_detail = nn.Sequential(\n",
    "             nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True), # è£œå›æœ€å¾Œçš„ 2x\n",
    "             nn.Conv2d(32, n_classes_detail, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def _block(self, in_c, out_c):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_c, out_c, 3, padding=1), nn.BatchNorm2d(out_c), nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, type_idx, z_pos, return_mode='both'):\n",
    "        # --- Encoder (ResNet) ---\n",
    "        # x: (B, 1, 512, 512)\n",
    "        x0 = self.enc_conv1(x)      # (B, 64, 256, 256)\n",
    "        x0 = self.enc_bn1(x0)\n",
    "        x0 = self.enc_relu(x0)\n",
    "        x1 = self.enc_maxpool(x0)   # (B, 64, 128, 128) -> Skip 1\n",
    "        \n",
    "        x2 = self.enc_layer1(x1)    # (B, 64, 128, 128) -> ResNet layer1 ä¸æ”¹è®Šå¤§å°\n",
    "        x3 = self.enc_layer2(x2)    # (B, 128, 64, 64)  -> Skip 2\n",
    "        x4 = self.enc_layer3(x3)    # (B, 256, 32, 32)  -> Skip 3\n",
    "        x5 = self.enc_layer4(x4)    # (B, 512, 16, 16)  -> Bottleneck\n",
    "        \n",
    "        # --- Injection ---\n",
    "        t_vec = self.type_emb(type_idx) \n",
    "        p_vec = self.pos_emb(z_pos.unsqueeze(1))\n",
    "        cond = torch.cat([t_vec, p_vec], dim=1)\n",
    "        cond = cond.unsqueeze(2).unsqueeze(3).expand(-1, -1, x5.shape[2], x5.shape[3])\n",
    "        \n",
    "        x5 = torch.cat([x5, cond], dim=1)\n",
    "        x5 = self.fusion(x5) # (B, 512, 16, 16)\n",
    "        \n",
    "        # --- Decoder ---\n",
    "        # x5 (16x16) + x4 (32x32)\n",
    "        d1 = self.up1(torch.cat([self.up(x5), x4], dim=1)) # (B, 256, 32, 32)\n",
    "        \n",
    "        # d1 (32x32) + x3 (64x64)\n",
    "        d2 = self.up2(torch.cat([self.up(d1), x3], dim=1)) # (B, 128, 64, 64)\n",
    "        \n",
    "        # d2 (64x64) + x2 (128x128) [æ³¨æ„: x2 å’Œ x1 å…¶å¯¦æ˜¯åŒä¸€å±¤ç´šï¼Œé€™è£¡é¸ x2 æ¥]\n",
    "        d3 = self.up3(torch.cat([self.up(d2), x2], dim=1)) # (B, 64, 128, 128)\n",
    "        \n",
    "        # d3 (128x128) -> (256x256)\n",
    "        d4 = self.up4(self.up(d3)) # (B, 32, 256, 256)\n",
    "        \n",
    "        # Heads å…§å«æœ€å¾Œçš„ Upsample (256 -> 512)\n",
    "        \n",
    "        if return_mode == 'rough':\n",
    "            return self.head_rough(d4)\n",
    "        elif return_mode == 'detail':\n",
    "            return self.head_detail(d4)\n",
    "        elif return_mode == 'both':\n",
    "            return self.head_rough(d4), self.head_detail(d4)\n",
    "            \n",
    "    # --- Helper Methods ---\n",
    "    def freeze_encoder_and_rough(self):\n",
    "        print(\"ğŸ”’ Freezing ResNet Encoder & Rough Head...\")\n",
    "        # å‡çµ ResNet éƒ¨åˆ†\n",
    "        for param in self.enc_conv1.parameters(): param.requires_grad = False\n",
    "        for param in self.enc_bn1.parameters(): param.requires_grad = False\n",
    "        for param in self.enc_layer1.parameters(): param.requires_grad = False\n",
    "        for param in self.enc_layer2.parameters(): param.requires_grad = False\n",
    "        for param in self.enc_layer3.parameters(): param.requires_grad = False\n",
    "        for param in self.enc_layer4.parameters(): param.requires_grad = False\n",
    "        \n",
    "        # å‡çµ Embedding & Fusion\n",
    "        for param in self.type_emb.parameters(): param.requires_grad = False\n",
    "        for param in self.pos_emb.parameters(): param.requires_grad = False\n",
    "        for param in self.fusion.parameters(): param.requires_grad = False\n",
    "        \n",
    "        # å‡çµ Rough Head\n",
    "        for param in self.head_rough.parameters(): param.requires_grad = False\n",
    "        \n",
    "        # ç¢ºä¿ Detail Head æ˜¯é–‹å•Ÿçš„\n",
    "        for param in self.head_detail.parameters(): param.requires_grad = True\n",
    "        print(\"âœ… Done.\")\n",
    "\n",
    "    def unfreeze_all(self):\n",
    "        for param in self.parameters(): \n",
    "            param.requires_grad = True\n",
    "        print(\"ğŸ”“ All layers unfrozen.\")\n",
    "    \n",
    "    # æ³¨æ„: é€™å€‹æ–°æ¨¡å‹å·²ç¶“å…§å»º ImageNet æ¬Šé‡ï¼Œä¸éœ€è¦ load_pretrained_encoder\n",
    "    # ä½†ç‚ºäº†ç›¸å®¹ä½ çš„ codeï¼Œå¯ä»¥ç•™ä¸€å€‹ç©º function æˆ–ç”¨ä¾†è¼‰å…¥ä½ è‡ªå·±çš„ checkpoint\n",
    "    def load_pretrained_encoder(self, path):\n",
    "        print(\"â„¹ï¸ Note: This model uses ImageNet weights by default.\")\n",
    "        if os.path.exists(path):\n",
    "            print(f\"ğŸ”„ Loading checkpoint: {path}\")\n",
    "            state_dict = torch.load(path)\n",
    "            # éæ¿¾ä¸¦è¼‰å…¥... (åŒä¹‹å‰çš„é‚è¼¯)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff33fc0",
   "metadata": {},
   "source": [
    "#### Fine-tune Optimizer Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8865f38f",
   "metadata": {},
   "source": [
    "##### Differential Learning Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffb0f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Fine-tune Strategy Design] (Differential Learning Rates)\n",
    "def get_fine_tuning_optimizer(model, encoder_lr=1e-5, decoder_lr=1e-4):\n",
    "    \"\"\"\n",
    "    ç‚º Fine-tuning è¨­è¨ˆçš„å„ªåŒ–å™¨è¨­å®šï¼š\n",
    "    1. Encoder ä½¿ç”¨æ¥µå°çš„ LR (ä¿ç•™ Pre-train çŸ¥è­˜ï¼Œä½†å…è¨±å¾®èª¿) -> Post-train æ•ˆæœ\n",
    "    2. Decoder/Head ä½¿ç”¨è¼ƒå¤§çš„ LR (å¿«é€Ÿå­¸ç¿’ 12 é¡ç‰¹å¾µ)\n",
    "    \"\"\"\n",
    "    \n",
    "    # å€åˆ†åƒæ•¸ç¾¤çµ„\n",
    "    encoder_params = []\n",
    "    decoder_params = []\n",
    "    \n",
    "    # å®šç¾©å“ªäº›å±¤å±¬æ–¼ Encoder (æ ¹æ“š ConditionedResNetUNet çµæ§‹)\n",
    "    encoder_layers = ['inc', 'down1', 'down2', 'down3', 'down4', 'type_emb', 'pos_emb', 'fusion']\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        if not param.requires_grad:\n",
    "            continue\n",
    "            \n",
    "        # åˆ¤æ–·åƒæ•¸å±¬æ–¼ Encoder é‚„æ˜¯ Decoder\n",
    "        is_encoder = any(layer in name for layer in encoder_layers)\n",
    "        \n",
    "        if is_encoder:\n",
    "            encoder_params.append(param)\n",
    "        else:\n",
    "            decoder_params.append(param) # up1, up2, up3, up4, outc\n",
    "            \n",
    "    print(f\"ğŸ”§ Optimizer Groups Setup:\")\n",
    "    print(f\"   - Encoder Params: {len(encoder_params)} tensors (LR={encoder_lr}) -> Slow updates\")\n",
    "    print(f\"   - Decoder Params: {len(decoder_params)} tensors (LR={decoder_lr}) -> Fast learning\")\n",
    "\n",
    "    # å»ºç«‹å„ªåŒ–å™¨\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {'params': encoder_params, 'lr': encoder_lr},\n",
    "        {'params': decoder_params, 'lr': decoder_lr}\n",
    "    ])\n",
    "    \n",
    "    return optimizer\n",
    "\n",
    "# --- æ¸¬è©¦ä¸€ä¸‹ (Optional) ---\n",
    "# dummy_model = ConditionedResNetUNet(1, 12).to(DEVICE)\n",
    "# opt = get_fine_tuning_optimizer(dummy_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661328ea",
   "metadata": {},
   "source": [
    "#### mapping matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fd19b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchical_consistency_loss(logits_detail, logits_rough):\n",
    "    \"\"\"\n",
    "    è¨ˆç®—ä¸€è‡´æ€§ Loss:\n",
    "    å°‡ Detailed é æ¸¬é€é Mapping èšåˆå¾Œï¼Œæ‡‰è©²è¦è·Ÿ Rough é æ¸¬å¾ˆåƒã€‚\n",
    "    \"\"\"\n",
    "    # 1. å°‡ Logits è½‰ç‚ºæ©Ÿç‡åˆ†ä½ˆ (Softmax)\n",
    "    probs_detail = F.softmax(logits_detail, dim=1) # (B, 12, H, W)\n",
    "    probs_rough = F.softmax(logits_rough, dim=1)   # (B, 5, H, W)\n",
    "    \n",
    "    # 2. åŸ·è¡Œ Mapping (çŸ©é™£ä¹˜æ³•)\n",
    "    # èª¿æ•´ç¶­åº¦ä»¥é€²è¡ŒçŸ©é™£ä¹˜æ³•: (B, H, W, 12) x (12, 5) -> (B, H, W, 5)\n",
    "    probs_detail_permuted = probs_detail.permute(0, 2, 3, 1) \n",
    "    probs_projected = torch.matmul(probs_detail_permuted, MAPPING_MATRIX)\n",
    "    \n",
    "    # è½‰å› (B, 5, H, W)\n",
    "    probs_projected = probs_projected.permute(0, 3, 1, 2)\n",
    "    \n",
    "    # 3. è¨ˆç®—å…©åˆ†ä½ˆä¹‹é–“çš„å·®ç•° (KL Divergence æˆ– MSE)\n",
    "    # é€™è£¡ç”¨ MSE ç°¡å–®ç›´è§€ï¼šå¸Œæœ›æŠ•å½±å¾Œçš„æ©Ÿç‡åˆ†å¸ƒ = åŸå§‹ Rough æ©Ÿç‡åˆ†å¸ƒ\n",
    "    loss = F.mse_loss(probs_projected, probs_rough)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090698fa-a14b-449b-8df7-1a8dc8d3ea82",
   "metadata": {},
   "source": [
    "### 5. Phase 1: Pre-train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc12f0-2d86-4e40-af31-0ed508382867",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"   ğŸš€ START PHASE 1: PRE-TRAINING (ROUGH)\")\n",
    "print(\"   Target: 5 Classes (Rough Labels)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"   ğŸ“ log will be saved to: {ROUGH_LOSS_LOG}\")\n",
    "\n",
    "\n",
    "# 1. Setup Data (æŒ‡å®š mode='rough')\n",
    "train_ds = SliceMasterDataset(train_files, mode='rough', transform=train_transform)\n",
    "val_ds = SliceMasterDataset(val_files, mode='rough', transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=ROUGH_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_ds, batch_size=ROUGH_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(f\"Phase 1 Data: {len(train_ds)} train slices, {len(val_ds)} val slices\")\n",
    "\n",
    "# 2. Setup Model (æŒ‡å®š n_classes=5)\n",
    "model = ConditionedResNetUNet(\n",
    "    n_channels=IN_CHANNELS, \n",
    "    n_classes_rough=NUM_CLASSES_ROUGH,   # 5\n",
    "    n_classes_detail=NUM_CLASSES_DETAILED, # 12\n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    num_mri_types=NUM_MRI_TYPES\n",
    ").to(DEVICE)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ğŸ”¥ Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=ROUGH_LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler(\"cuda\") # æ··åˆç²¾åº¦è¨“ç·´\n",
    "\n",
    "# 3. Training Loop\n",
    "best_dice = 0.0\n",
    "history_rough = []\n",
    "\n",
    "for epoch in range(ROUGH_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # [Training]\n",
    "    # é€™è£¡è§£åŒ… 4 å€‹è®Šæ•¸: image, label, z_pos, type_idx\n",
    "    for images, masks, z_pos, type_idx in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{ROUGH_EPOCHS}\"):\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "        z_pos, type_idx = z_pos.to(DEVICE), type_idx.to(DEVICE)\n",
    "        \n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            # Forward\n",
    "            preds = model(images, type_idx, z_pos, return_mode='rough')\n",
    "            loss = criterion(preds, masks)\n",
    "            \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # [Validation]\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_dice = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks, z_pos, type_idx in val_loader:\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            z_pos, type_idx = z_pos.to(DEVICE), type_idx.to(DEVICE)\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                preds = model(images, type_idx, z_pos, return_mode='rough')\n",
    "                loss = criterion(preds, masks)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            # è¨ˆç®— Dice (ä½¿ç”¨ Cell 2 å®šç¾©çš„ function)\n",
    "            val_dice += dice_score(preds, masks, NUM_CLASSES_ROUGH)\n",
    "            \n",
    "    # è¨ˆç®—å¹³å‡æŒ‡æ¨™\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_dice = val_dice / len(val_loader)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    \n",
    "    # ç´€éŒ„æ­·å²    \n",
    "    history_rough.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_dice': avg_val_dice,\n",
    "        'time': duration\n",
    "    })\n",
    "    pd.DataFrame(history_rough).to_csv(ROUGH_LOSS_LOG, index=False)\n",
    "    \n",
    "    # [Save Best Model] é—œéµæ­¥é©Ÿï¼\n",
    "    if avg_val_dice > best_dice:\n",
    "        best_dice = avg_val_dice\n",
    "        state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "        torch.save(state_dict, ROUGH_MODEL_PATH)\n",
    "        print(f\"  ğŸ† Saved Best Model! (Dice: {best_dice:.4f}) -> {ROUGH_MODEL_PATH}\")\n",
    "    \n",
    "    plot_training_curves(ROUGH_LOSS_LOG, ROUGH_LOSS_IMG)\n",
    "    print(f\"Epoch {epoch+1} | T-Loss: {avg_train_loss:.4f} | V-Loss: {avg_val_loss:.4f} | V-Dice: {avg_val_dice:.4f} (Best: {best_dice:.4f})\")\n",
    "\n",
    "print(\"âœ… Phase 1 Training Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a30c25",
   "metadata": {},
   "source": [
    "### 6. Phase 1.5: Hierarchical Warm-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12987c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"   ğŸš€ START PHASE 1.5: HIERARCHICAL WARM-UP\")\n",
    "print(\"   Goal: Train Detail Head to align with Rough Head\")\n",
    "print(\"=\"*40)\n",
    "print(f\"   ğŸ“ log will be saved to: {WARMUP_LOSS_LOG}\")\n",
    "\n",
    "# 1. è³‡æ–™éæ¿¾ (åªç”¨æœ‰ Detail çš„è³‡æ–™)\n",
    "print(\"Filtering detailed data...\")\n",
    "train_files_detail = [f for f in train_files if np.load(f, allow_pickle=True).item().get('has_detail', False)]\n",
    "val_files_detail = [f for f in val_files if np.load(f, allow_pickle=True).item().get('has_detail', False)]\n",
    "print(f\"Detail Train: {len(train_files_detail)} | Detail Val: {len(val_files_detail)}\")\n",
    "\n",
    "# Setup Data (Mode='detail')\n",
    "train_ds_warmup = SliceMasterDataset(train_files_detail, mode='detail', transform=train_transform)\n",
    "train_loader_warmup = DataLoader(train_ds_warmup, batch_size=WARMUP_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "# é©—è­‰é›†: ä¸åš Augmentation (transform=None)\n",
    "val_ds_warmup = SliceMasterDataset(val_files_detail, mode='detail', transform=val_transform)\n",
    "val_loader_warmup = DataLoader(val_ds_warmup, batch_size=WARMUP_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "model = ConditionedResNetUNet(\n",
    "    n_channels=IN_CHANNELS, \n",
    "    n_classes_rough=NUM_CLASSES_ROUGH, \n",
    "    n_classes_detail=NUM_CLASSES_DETAILED, \n",
    "    embed_dim=EMBEDDING_DIM, \n",
    "    num_mri_types=NUM_MRI_TYPES\n",
    ").to(DEVICE)\n",
    "\n",
    "# 3. è¼‰å…¥ Phase 1 æ¬Šé‡\n",
    "model.load_pretrained_encoder(ROUGH_MODEL_PATH)\n",
    "\n",
    "# 4. å‡çµ Encoder å’Œ Rough Head (è€å¸«ä¸å‡†å‹•)\n",
    "model.freeze_encoder_and_rough()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ğŸ”¥ Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "# 5. å®šç¾©å¸¶æ¬Šé‡çš„ Loss (Crucial for AM Muscle!)\n",
    "# 0:BG, 6:AM -> åŠ å¼· AM æ¬Šé‡\n",
    "warmup_weights = torch.ones(NUM_CLASSES_DETAILED).to(DEVICE)\n",
    "warmup_weights[6] = 2.0 \n",
    "criterion_warmup = nn.CrossEntropyLoss(weight=warmup_weights)\n",
    "\n",
    "# 6. Optimizer (åªæ›´æ–° head_detail)\n",
    "optimizer_warmup = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=WARMUP_LR)\n",
    "scaler = torch.amp.GradScaler(\"cuda\") # æ··åˆç²¾åº¦è¨“ç·´\n",
    "history_warmup = []\n",
    "\n",
    "# 7. Training Loop (Warm-up)\n",
    "print(f\"ğŸ”¥ Starting Warm-up for {WARMUP_EPOCHS} epochs...\")\n",
    "for epoch in range(WARMUP_EPOCHS): # çŸ­æš«è¨“ç·´å³å¯ (e.g., 5-10 epochs)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_loss_ce = 0\n",
    "    train_loss_consist = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader_warmup, desc=f\"Warm-up Epoch {epoch+1}/{WARMUP_EPOCHS}\")\n",
    "    \n",
    "    for images, mask_detail, z_pos, type_idx in pbar:\n",
    "        images, mask_detail = images.to(DEVICE), mask_detail.to(DEVICE)\n",
    "        z_pos, type_idx = z_pos.to(DEVICE), type_idx.to(DEVICE)\n",
    "        \n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            # Forward (å–å¾—å…©çµ„ Logits)\n",
    "            logits_rough, logits_detail = model(images, type_idx, z_pos, return_mode='both')\n",
    "            \n",
    "            # Loss 1: Detailed Head è¦é æ¸¬æ­£ç¢º (Cross Entropy)\n",
    "            loss_ce = criterion_warmup(logits_detail, mask_detail)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # Loss 2: Consistency Constraint (Student -> Teacher)\n",
    "                # é€™è£¡æˆ‘å€‘ä¿¡ä»» Rough Head çš„åˆ¤æ–· (å› ç‚ºå®ƒæ˜¯ Phase 1 è¨“ç·´å¥½çš„è€å¸«)\n",
    "                teacher_logits = logits_rough \n",
    "            loss_consist = hierarchical_consistency_loss(logits_detail, teacher_logits)\n",
    "            \n",
    "            # Total Loss\n",
    "            loss = loss_ce + 0.5 * loss_consist # 0.5 æ˜¯æ¬Šé‡ï¼Œå¯èª¿æ•´\n",
    "            \n",
    "        optimizer_warmup.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer_warmup)\n",
    "        scaler.update()\n",
    "        \n",
    "        # è¨˜éŒ„æ•¸æ“š\n",
    "        train_loss += loss.item()\n",
    "        train_loss_ce += loss_ce.item()\n",
    "        train_loss_consist += loss_consist.item()\n",
    "        \n",
    "        pbar.set_postfix({'L': loss.item(), 'CE': loss_ce.item(), 'C': loss_consist.item()})\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader_warmup)\n",
    "\n",
    "    # --- [Validation] ---\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_loss_ce = 0\n",
    "    val_loss_consist = 0\n",
    "    val_dice = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks, z_pos, type_idx in val_loader_warmup:\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            z_pos, type_idx = z_pos.to(DEVICE), type_idx.to(DEVICE)\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                logits_rough, logits_detail = model(images, type_idx, z_pos, return_mode='both')\n",
    "                \n",
    "                l_ce = criterion_warmup(logits_detail, masks)\n",
    "                l_consist = hierarchical_consistency_loss(logits_detail, logits_rough)\n",
    "                l_total = l_ce + CONSISTENCY_WEIGHT * l_consist\n",
    "            \n",
    "            val_loss += l_total.item()\n",
    "            val_loss_ce += l_ce.item()\n",
    "            val_loss_consist += l_consist.item()\n",
    "            preds = model(images, type_idx, z_pos, return_mode='detail')\n",
    "            val_dice += dice_score(preds, masks, NUM_CLASSES_DETAILED)\n",
    "            \n",
    "    avg_val_loss = val_loss / len(val_loader_warmup)\n",
    "    avg_val_ce = val_loss_ce / len(val_loader_warmup)\n",
    "    avg_val_consist = val_loss_consist / len(val_loader_warmup)\n",
    "    avg_val_dice = val_dice / len(val_loader_warmup)\n",
    "    \n",
    "    # ç´€éŒ„æ­·å²\n",
    "    history_warmup.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_ce': avg_val_ce,\n",
    "        'val_consist': avg_val_consist,\n",
    "        'val_dice': avg_val_dice\n",
    "    })\n",
    "    pd.DataFrame(history_warmup).to_csv(WARMUP_LOSS_LOG, index=False)\n",
    "    plot_training_curves(WARMUP_LOSS_LOG, WARMUP_LOSS_IMG)\n",
    "        \n",
    "    print(f\"Warmup {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} (CE: {avg_val_ce:.4f}, Consist: {avg_val_consist:.4f})\")\n",
    "\n",
    "# å­˜ä¸‹ Warm-up å¾Œçš„æ¬Šé‡ï¼Œçµ¦ Step 2 ç”¨\n",
    "state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "torch.save(state_dict, WARMUP_MODEL_PATH)\n",
    "print(\"Phase 1.5 Complete. Detail Head Initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6fd523",
   "metadata": {},
   "source": [
    "### 7. Phase 2: Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dbbab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"   ğŸš€ START PHASE 2: FINE-TUNING (DETAIL)\")\n",
    "print(f\"   Target: {NUM_CLASSES_DETAILED} Classes (Detailed Labels)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"   ğŸ“ log will be saved to: {DETAIL_LOSS_LOG}\")\n",
    "\n",
    "# ==========================================\n",
    "# 0. è³‡æ–™éæ¿¾ (Crucial Step!)\n",
    "# ==========================================\n",
    "# æˆ‘å€‘åªè¨“ç·´é‚£äº›çœŸæ­£æ“æœ‰ Detailed Label çš„åˆ‡ç‰‡\n",
    "# é€™ä¸€æ­¥æœƒè®€å–æ‰€æœ‰ .npy headerï¼Œå¯èƒ½æœƒèŠ±ä¸€é»æ™‚é–“ï¼Œä½†éå¸¸æœ‰å¿…è¦\n",
    "print(\"ğŸ” Filtering dataset for detailed labels... (This may take a moment)\")\n",
    "\n",
    "train_files_detail = [f for f in train_files if np.load(f, allow_pickle=True).item().get('has_detail', False)]\n",
    "val_files_detail = [f for f in val_files if np.load(f, allow_pickle=True).item().get('has_detail', False)]\n",
    "print(f\"Detailed Train: {len(train_files_detail)} | Detailed Val: {len(val_files_detail)}\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. Setup Data (Detail Mode)\n",
    "# ==========================================\n",
    "train_ds = SliceMasterDataset(train_files_detail, mode='detail', transform=train_transform)\n",
    "val_ds = SliceMasterDataset(val_files_detail, mode='detail', transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=DETAIL_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader = DataLoader(val_ds, batch_size=DETAIL_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Setup Model (12 Classes)\n",
    "# ==========================================\n",
    "model = ConditionedResNetUNet(\n",
    "    n_channels=IN_CHANNELS, \n",
    "    n_classes_rough=NUM_CLASSES_ROUGH, \n",
    "    n_classes_detail=NUM_CLASSES_DETAILED, \n",
    "    embed_dim=EMBEDDING_DIM, \n",
    "    num_mri_types=NUM_MRI_TYPES\n",
    ").to(DEVICE)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Load Pretrained Weights (Surgery)\n",
    "# ==========================================\n",
    "\n",
    "if os.path.exists(WARMUP_MODEL_PATH):\n",
    "    print(f\"ğŸ”„ Loading pretrained weights from: {WARMUP_MODEL_PATH}\")\n",
    "    model.load_state_dict(torch.load(WARMUP_MODEL_PATH))\n",
    "    print(\"âœ… Weights loaded from Phase 1.5\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"âŒ Phase 1.5 model not found at {WARMUP_MODEL_PATH}.\")\n",
    "\n",
    "# [é—œéµ] å…¨é¢è§£å‡ (å› ç‚º Phase 1.5 çµæŸæ™‚æ˜¯å‡çµçš„)\n",
    "model.unfreeze_all()\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ğŸ”¥ Using {torch.cuda.device_count()} GPUs!\")\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "# ==========================================\n",
    "# 4. Optimizer & Weighted Loss\n",
    "# ==========================================\n",
    "optimizer = get_fine_tuning_optimizer(model, encoder_lr=DETAIL_LR_ENCODER, decoder_lr=DETAIL_LR_DECODER)\n",
    "# [é—œéµç­–ç•¥] Class Weighting\n",
    "# å› ç‚º AM (Class 6) ä¹‹å‰è¢«ç•¶ä½œèƒŒæ™¯ï¼Œæˆ‘å€‘è¦çµ¦å®ƒæ›´é«˜çš„æ¬Šé‡ï¼Œå¼·è¿«æ¨¡å‹é—œæ³¨å®ƒ\n",
    "# 0:BG, 1:SA, ..., 6:AM, ...\n",
    "class_weights = torch.ones(NUM_CLASSES_DETAILED).to(DEVICE)\n",
    "class_weights[6] = 2.0  # å° AM åŠ æ¬Š (å¯æ ¹æ“šé©—è­‰çµæœèª¿æ•´ï¼Œä¾‹å¦‚ 1.5 ~ 3.0)\n",
    "class_weights[0] = 0.5  # é™ä½èƒŒæ™¯æ¬Šé‡ (é¸æ“‡æ€§)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "scaler = torch.amp.GradScaler(\"cuda\") # æ··åˆç²¾åº¦è¨“ç·´\n",
    "\n",
    "# ==========================================\n",
    "# 5. Training Loop\n",
    "# ==========================================\n",
    "best_dice = 0.0\n",
    "history_detail = []\n",
    "print(f\"Start Fine-tuning for {DETAIL_EPOCHS} epochs...\")\n",
    "\n",
    "for epoch in range(DETAIL_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    # [Training]\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{DETAIL_EPOCHS}\")\n",
    "    \n",
    "     # é€™è£¡è§£åŒ… 4 å€‹è®Šæ•¸: image, label, z_pos, type_idx\n",
    "    for images, masks, z_pos, type_idx in pbar:\n",
    "        images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "        z_pos, type_idx = z_pos.to(DEVICE), type_idx.to(DEVICE)\n",
    "        \n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            preds = model(images, type_idx, z_pos, return_mode='detail')\n",
    "            loss = criterion(preds, masks)\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # [Validation]\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_dice = 0\n",
    "    with torch.no_grad():\n",
    "        for images, masks, z_pos, type_idx in val_loader:\n",
    "            images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "            z_pos, type_idx = z_pos.to(DEVICE), type_idx.to(DEVICE)\n",
    "                        \n",
    "            with torch.amp.autocast(\"cuda\"):\n",
    "                preds = model(images, type_idx, z_pos, return_mode='detail')\n",
    "                loss = criterion(preds, masks)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            # é€™è£¡è¨ˆç®— 12 é¡çš„ Dice\n",
    "            val_dice += dice_score(preds, masks, NUM_CLASSES_DETAILED)\n",
    "            \n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_dice = val_dice / len(val_loader)\n",
    "    \n",
    "    duration = time.time() - start_time\n",
    "    # ç´€éŒ„æ­·å²\n",
    "    history_detail.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': avg_train_loss,\n",
    "        'val_loss': avg_val_loss,\n",
    "        'val_dice': avg_val_dice,\n",
    "        'time': duration\n",
    "    })\n",
    "    pd.DataFrame(history_detail).to_csv(DETAIL_LOSS_LOG, index=False)\n",
    "    plot_training_curves(DETAIL_LOSS_LOG, DETAIL_LOSS_IMG)\n",
    "    print(f\"Epoch {epoch+1} | T-Loss: {avg_train_loss:.4f} | V-Loss: {avg_val_loss:.4f} | V-Dice: {avg_val_dice:.4f} | Time: {duration:.1f}s\")\n",
    "    \n",
    "    # [Save Best]\n",
    "    if avg_val_dice > best_dice:\n",
    "        best_dice = avg_val_dice\n",
    "        state_dict = model.module.state_dict() if isinstance(model, nn.DataParallel) else model.state_dict()\n",
    "        torch.save(state_dict, DETAIL_MODEL_PATH)\n",
    "        print(f\"  ğŸ† Saved Best Detail Model! (Dice: {best_dice:.4f})\")\n",
    "\n",
    "print(\"Phase 2 Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e5aa1b",
   "metadata": {},
   "source": [
    "### 8. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bc4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = glob.glob(os.path.join(TEST_DATA_DIR, \"*.npy\"))\n",
    "if len(test_files) == 0:\n",
    "    raise FileNotFoundError(f\"âŒ No .npy files found in {TEST_DATA_DIR}. Please check the path!\")\n",
    "\n",
    "print(f\"Found {len(test_files)} slices in Test Set.\")\n",
    "test_detail = []\n",
    "test_without_detail = []\n",
    "for i in test_files:\n",
    "    data = np.load(i, allow_pickle=True).item()\n",
    "    if data.get('has_detail'):\n",
    "        test_detail.append(i)\n",
    "    else:\n",
    "        test_without_detail.append(i)\n",
    "print(f\"  - With Detailed Labels: {len(test_detail)} slices\")\n",
    "print(f\"  - Without Detailed Labels: {len(test_without_detail)} slices\")\n",
    "        \n",
    "# å»ºç«‹ Dataset èˆ‡ Loader\n",
    "# æ³¨æ„: mode='detail', transform=None (æ¸¬è©¦é›†ä¸åšå¢å¼·)\n",
    "test_ds = SliceMasterDataset(test_detail, mode='detail', transform=val_transform)\n",
    "test_loader = DataLoader(test_ds, batch_size=EVAL_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "# ==========================================\n",
    "# 2. è¼‰å…¥æ¨¡å‹\n",
    "# ==========================================\n",
    "model = ConditionedResNetUNet(\n",
    "    n_channels=IN_CHANNELS, \n",
    "    n_classes_rough=NUM_CLASSES_ROUGH, \n",
    "    n_classes_detail=NUM_CLASSES_DETAILED, \n",
    "    embed_dim=EMBEDDING_DIM,\n",
    "    num_mri_types=NUM_MRI_TYPES\n",
    ").to(DEVICE)\n",
    "\n",
    "if os.path.exists(EVAL_MODEL_PATH):\n",
    "    print(f\"ğŸ”„ Loading weights from: {EVAL_MODEL_PATH}\")\n",
    "    state_dict = torch.load(EVAL_MODEL_PATH, map_location=DEVICE, weights_only=False)\n",
    "    model.load_state_dict(state_dict)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"âŒ Model weight not found at {EVAL_MODEL_PATH}\")\n",
    "model.eval()\n",
    "\n",
    "# ================= 3. æ¨è«–èˆ‡æ•¸æ“šæ”¶é›† =================\n",
    "# å„²å­˜çµæ§‹: metrics[Sequence][Muscle_ID] = [dice1, dice2, ...]\n",
    "metrics_data = defaultdict(lambda: defaultdict(list))\n",
    "viz_results = []  # å„²å­˜è¦ç•«åœ–çš„è³‡æ–™\n",
    "print(\"ğŸš€ Starting Inference on Test Set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (images, labels, z_pos, type_idx) in enumerate(tqdm(test_loader)):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        z_pos = z_pos.to(DEVICE)\n",
    "        type_idx = type_idx.to(DEVICE)\n",
    "        \n",
    "        # å–å¾—ç•¶å‰çš„ MRI Type ID\n",
    "        current_type_id = type_idx.item()\n",
    "        \n",
    "        # æ¨è«– (return_mode='detail')\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            out_det = model(images, type_idx, z_pos, return_mode='detail')\n",
    "        \n",
    "        pred_det = torch.argmax(out_det, dim=1)\n",
    "        \n",
    "        # --- è¨ˆç®—æ¯å€‹è‚Œè‚‰çš„ Dice ä¸¦å­˜èµ·ä¾† ---\n",
    "        slice_dices = []\n",
    "        for c in range(1, NUM_CLASSES_DETAILED): # 1~11 (Skip BG)\n",
    "            pred_mask = (pred_det == c)\n",
    "            true_mask = (labels == c)\n",
    "            \n",
    "            inter = (pred_mask & true_mask).sum().item()\n",
    "            union = (pred_mask.sum() + true_mask.sum()).item()\n",
    "            \n",
    "            # åªæœ‰ç•¶ GT æœ‰è©²è‚Œè‚‰æ™‚æ‰ç´å…¥çµ±è¨ˆ\n",
    "            if true_mask.sum() > 0:\n",
    "                dice_val = 2 * inter / (union + 1e-6)\n",
    "                metrics_data[current_type_id][c].append(dice_val)\n",
    "                slice_dices.append(dice_val)\n",
    "            \n",
    "        # --- æ”¶é›†è¦–è¦ºåŒ–è³‡æ–™ (éš¨æ©ŸæŠ½æ¨£) ---\n",
    "        if idx % VIZ_INTERVAL == 0:\n",
    "            avg_slice_dice = np.mean(slice_dices) if slice_dices else 0.0\n",
    "            type_name = ID_TO_TYPE.get(current_type_id, str(current_type_id))\n",
    "            \n",
    "            viz_results.append({\n",
    "                'type_name': type_name,\n",
    "                'z': z_pos.item(),\n",
    "                'img': images[0, 0].cpu().numpy(),\n",
    "                'gt': labels[0].cpu().numpy(),\n",
    "                'pred': pred_det[0].cpu().numpy(),\n",
    "                'dice': avg_slice_dice\n",
    "            })\n",
    "\n",
    "# ================= 4. ç”¢ç”Ÿå ±è¡¨ =================\n",
    "# Rows: Muscle Names, Cols: Sequences\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"   Test Set Evaluation Report (Dice Score)\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "final_table = {}\n",
    "all_types_in_data = sorted(metrics_data.keys())\n",
    "\n",
    "for c in range(1, NUM_CLASSES_DETAILED):\n",
    "    muscle_name = MUSCLE_NAMES.get(c, f\"Muscle_{c}\")\n",
    "    row_data = {}\n",
    "    for t_id in all_types_in_data:\n",
    "        dices = metrics_data[t_id][c]\n",
    "        mean_dice = np.mean(dices) if dices else 0.0\n",
    "        \n",
    "        col_name = ID_TO_TYPE.get(t_id, str(t_id))\n",
    "        row_data[col_name] = mean_dice\n",
    "    final_table[muscle_name] = row_data\n",
    "\n",
    "df_metrics = pd.DataFrame(final_table).T \n",
    "df_metrics = df_metrics.sort_index()\n",
    "\n",
    "# é‡æ–°æ’åºæ¬„ä½\n",
    "target_order = ['Fat', 'STIR', 'T1', 'T2', 'Water']\n",
    "df_metrics = df_metrics.reindex(columns=target_order)  \n",
    "\n",
    "# åŠ å…¥å¹³å‡\n",
    "df_metrics.loc['AVERAGE'] = df_metrics.mean()\n",
    "\n",
    "# é¡¯ç¤ºæ¼‚äº®çš„è¡¨æ ¼\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(\"æ•¸å€¼ç‚º Mean Dice Score:\")\n",
    "display(df_metrics)\n",
    "\n",
    "# å­˜æª”\n",
    "df_metrics.to_csv(EVAL_CSV_OUTPUT)\n",
    "print(f\"\\nè©•ä¼°è¡¨å·²å„²å­˜è‡³: {EVAL_CSV_OUTPUT}\")\n",
    "\n",
    "# ================= 5. è¦–è¦ºåŒ–å±•ç¤º =================\n",
    "if viz_results:\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    # print(f\"   å€‹æ¡ˆåˆ‡ç‰‡è¦–è¦ºåŒ– (First / Middle / Last)\")\n",
    "    print(f\"Sampled every {VIZ_INTERVAL} slices from Test Set\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    for item in viz_results:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        title_fs = 11\n",
    "        \n",
    "        # Raw Image\n",
    "        axs[0].imshow(item['img'], cmap='gray')\n",
    "        axs[0].set_title(f\"{item['type_name']} | Z={item['z']:.2f}\", fontsize=title_fs)\n",
    "        axs[0].axis('off')\n",
    "        \n",
    "        # Ground Truth\n",
    "        axs[1].imshow(item['img'], cmap='gray')\n",
    "        axs[1].imshow(item['gt'], cmap=VIZ_CMAP, norm=VIZ_NORM, alpha=0.6, interpolation='nearest')\n",
    "        axs[1].set_title(\"Ground Truth\", fontsize=title_fs)\n",
    "        axs[1].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        axs[2].imshow(item['img'], cmap='gray')\n",
    "        axs[2].imshow(item['pred'], cmap=VIZ_CMAP, norm=VIZ_NORM, alpha=0.6, interpolation='nearest')\n",
    "        axs[2].set_title(f\"Prediction (Dice: {item['dice']:.2f})\", fontsize=title_fs)\n",
    "        axs[2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No visualization samples generated. Check VIZ_INTERVAL or data size.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89c4be9-a9e0-4f82-8ed0-4fdf45bf15e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_metrics = pd.read_csv(EVAL_CSV_OUTPUT, index_col=0)\n",
    "\n",
    "print(df_metrics.index)\n",
    "\n",
    "avg_row = df_metrics.loc[['AVERAGE']]\n",
    "\n",
    "other_rows = df_metrics.drop('AVERAGE')\n",
    "\n",
    "df_metrics = pd.concat([avg_row, other_rows])\n",
    "\n",
    "flat = df_metrics.stack()  # è®Šæˆ MultiIndex Series (row, col)\n",
    "flat.index = [f\"{row}_{col}\" for row, col in flat.index]  # åˆä½µåç¨±\n",
    "flat_df = flat.to_frame().T  # è½‰æˆä¸€åˆ— DataFrame\n",
    "\n",
    "flat_df.to_csv(FLATTENED_METRICS_OUTPUT, index=False)\n",
    "print(f\"Flattened metrics saved to '{FLATTENED_METRICS_OUTPUT}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
