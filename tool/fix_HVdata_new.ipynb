{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c82f74",
   "metadata": {},
   "source": [
    "## stitch HV data ( image & rough label) in MyoSegmenTUM & update csv\n",
    "- 發現 MyoSegmenTUM 下的 `HV 開頭` 的 data 是分段的，所以嘗試將兩段黏起來\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774f2b10",
   "metadata": {},
   "source": [
    "### Configuration **將 csv column name 中具有空格的地方改成 \"_\" **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b9d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from collections import defaultdict\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.patches as mpatches\n",
    "import glob\n",
    "import random\n",
    "import numpy.ma as ma\n",
    "\n",
    "# --- 全域設定 (Global Configurations) ---\n",
    "# 1. 專案根目錄 (Project Root)\n",
    "PROJECT_ROOT = \"/home/n26141826/114-1_TAICA_cv_Final_Project\"\n",
    "\n",
    "# 2. 原始資料設定 (Raw Data Input)\n",
    "RAW_DATA_FOLDER = os.path.join(PROJECT_ROOT, \"data\", \"data\")\n",
    "RAW_CSV_FILE = os.path.join(RAW_DATA_FOLDER, \"metadata_3D.csv\")\n",
    "\n",
    "# 3. 拼接處理設定 (Stitching Output)\n",
    "# 拼接後的 3D 檔案與新 CSV 要存哪裡\n",
    "FIXED_DATA_ROOT = os.path.join(PROJECT_ROOT, \"data2\", \"data_fixed\")\n",
    "OUTPUT_CSV_FILE = os.path.join(FIXED_DATA_ROOT, \"metadata_3D_stitched.csv\")\n",
    "\n",
    "# 4. 2D 切片輸出設定 (2D Slices Output)\n",
    "# 這是最終 PyTorch Dataset 要讀取的 .npy 檔案位置\n",
    "OUTPUT_SLICE_DIR = os.path.join(PROJECT_ROOT, \"data2\", \"npy_Embedding\")\n",
    "\n",
    "# 5. csv 欄位名稱設定 (CSV Column Names)\n",
    "DATASET = \"Dataset\"\n",
    "PHENOTYPE = \"Phenotype\"\n",
    "MRI_SAMPLRE = \"MRI_sample\" \n",
    "MRI_SEQUENCE = \"MRI_Sequence\"                 # 我把空格改成底線了\n",
    "IMAGE_3D_FILE = \"image_3D_file\"               # 我把空格改成底線了\n",
    "ROUGH_LABEL_3D_FILE = \"rough_label_3D_file\"\n",
    "DETAILED_LABEL_3D_FILE = \"detailed_label_3D_file\"\n",
    "# 6. 資料篩選條件 (Data Filter)\n",
    "TARGET_DATASET = 'MyoSegmenTUM'\n",
    "TARGET_PHENOTYPE = 'Control'\n",
    "\n",
    "# 7. MRI 序列映射表 (Modality Mapping)\n",
    "# String -> Int ID\n",
    "TYPE_MAP = {\n",
    "    'Water': 0,\n",
    "    'Fat': 1,\n",
    "    'FATFRACTION': 1, # 通常將 Fat Fraction 視為 Fat 類別，或依你需求改為獨立 ID\n",
    "    'T1': 2,\n",
    "    'T2': 3,\n",
    "    'STIR': 4\n",
    "}\n",
    "# position-embedding 用的類別數量 \n",
    "# -> 0 : 屁股\n",
    "# -> 1 : 膝蓋\n",
    "\n",
    "POSITION_ROUGH_EMBEDDING_COLORS = [\n",
    "    '#000000', # 0: BG\n",
    "    '#e6194b', # 1: SA\n",
    "    '#006400', # 2: RF (Green)\n",
    "    '#228B22', # 3: VL (Green)\n",
    "    '#32CD32', # 4: VI (Green)\n",
    "    '#7CFC00'  # 5: VM (Green)\n",
    "]\n",
    "POSITION_DETAILED_EMBEDDING_COLORS = [\n",
    "    '#000000', # 0: BG\n",
    "    '#e6194b', # 1: SA\n",
    "    '#006400', # 2: RF (Green)\n",
    "    '#228B22', # 3: VL (Green)\n",
    "    '#32CD32', # 4: VI (Green)\n",
    "    '#7CFC00', # 5: VM (Green)\n",
    "    '#911eb4', # 6: AM (Purple)\n",
    "    '#46f0f0', # 7: GR (Cyan)\n",
    "    '#00008B', # 8: BFL (Blue)\n",
    "    '#0000CD', # 9: ST (Blue)\n",
    "    '#4169E1', # 10: SM (Blue)\n",
    "    '#87CEEB'  # 11: BFS (Blue)\n",
    "]\n",
    "ROUGH_MUSCLE_NAMES = {\n",
    "    0: 'Background', 1: 'Sartorius', 2: 'Rectus Femoris', 3: 'Vastus Lateralis',\n",
    "    4: 'Vastus Intermedius', 5: 'Vastus Medialis'\n",
    "}\n",
    "DETAIL_MUSCLE_NAMES = {\n",
    "    0: 'Background', 1: 'Sartorius', 2: 'Rectus Femoris', 3: 'Vastus Lateralis',\n",
    "    4: 'Vastus Intermedius', 5: 'Vastus Medialis', 6: 'Adductor Magnus',\n",
    "    7: 'Gracilis', 8: 'Biceps Femoris LH', 9: 'Semitendinosus',\n",
    "    10: 'Semimembranosus', 11: 'Biceps Femoris SH'\n",
    "}\n",
    "# --- 自動建立資料夾 (Auto-create Dirs) ---\n",
    "for d in [FIXED_DATA_ROOT, OUTPUT_SLICE_DIR,OUTPUT_SLICE_DIR+'/train',OUTPUT_SLICE_DIR+'/test']:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"✅ Configuration Loaded Successfully!\")\n",
    "print(f\"- Raw CSV: {RAW_CSV_FILE}\")\n",
    "print(f\"- Output Stitched CSV: {OUTPUT_CSV_FILE}\")\n",
    "print(f\"- Final 2D Output Dir: {OUTPUT_SLICE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36151ce",
   "metadata": {},
   "source": [
    "### 1. copy original dataset (2D+3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff46daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(FIXED_DATA_ROOT) and os.path.isdir(FIXED_DATA_ROOT):\n",
    "    shutil.rmtree(FIXED_DATA_ROOT)\n",
    "    \n",
    "shutil.copytree(RAW_DATA_FOLDER, FIXED_DATA_ROOT)\n",
    "print(f\"Copied dataset folder to {FIXED_DATA_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33530480",
   "metadata": {},
   "source": [
    "\n",
    "### 2. delete whole MyoSegmenTUM in copied 3D file (image + rough label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69417d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# read csv from copied folder and write new csv into fixed folder\n",
    "df = pd.read_csv(RAW_CSV_FILE, sep=',')\n",
    "# print(df.head(2))\n",
    "for index, row in df.iterrows():\n",
    "    dataset = row[DATASET]\n",
    "    # process path\n",
    "    if dataset == TARGET_DATASET:\n",
    "        img_path = row[IMAGE_3D_FILE]\n",
    "        rough_path = row[ROUGH_LABEL_3D_FILE]\n",
    "        img_full_path = os.path.join(FIXED_DATA_ROOT, img_path.replace('\\\\', '/'))\n",
    "        rough_full_path =  os.path.join(FIXED_DATA_ROOT, rough_path.replace('\\\\', '/'))\n",
    "        # delete image and rough label .nii.gz files\n",
    "        if os.path.exists(img_full_path):\n",
    "            os.remove(img_full_path)\n",
    "            print(f\"Deleted image file: {img_full_path}\")\n",
    "        if os.path.exists(rough_full_path):\n",
    "            os.remove(rough_full_path)\n",
    "            print(f\"Deleted rough label file: {rough_full_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d370bd",
   "metadata": {},
   "source": [
    "### 3. stitch HV data in MyoSegmenTUM\n",
    "### 4. add them in to 3D dataset \n",
    "### 5. fix `metadata_3D.csv` in copied folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvThighStitcher:\n",
    "    def __init__(self, csv_path):\n",
    "        self.csv_path = csv_path\n",
    "        # Regex: (排序號碼)_(群組名稱).nii\n",
    "        self.pattern = re.compile(r\"^(\\d+)_(.+)\\.nii(\\.gz)?$\")\n",
    "\n",
    "    def parse_csv_and_group(self, data_folder):\n",
    "        \"\"\"\n",
    "        讀取 CSV 並將 Image 與 Label 綁定在一起分組\n",
    "        Return:\n",
    "            groups: dict\n",
    "            Key = 'HV011_FATFRACTION'\n",
    "            Value = list of tuples: (sort_num, img_path, rough_path, raw_row_series)\n",
    "        \"\"\"\n",
    "        print(f\"Reading CSV: {self.csv_path}\")\n",
    "        df = pd.read_csv(self.csv_path, sep=',') \n",
    "        \n",
    "        # Filter\n",
    "        target_df = df[(df[DATASET] == TARGET_DATASET) & (df[PHENOTYPE] == TARGET_PHENOTYPE)]\n",
    "        print(f\"Found {len(target_df)} rows for 'MyoSegmenTUM' & 'Control'.\")\n",
    "\n",
    "        groups = defaultdict(list)\n",
    "        \n",
    "        for idx, row in target_df.iterrows():\n",
    "            img_path = row[IMAGE_3D_FILE]\n",
    "            rough_path = row[ROUGH_LABEL_3D_FILE]\n",
    "            \n",
    "            # 處理路徑分隔符號\n",
    "            imgname = img_path.replace('\\\\', '/').split('/')[-1]\n",
    "            # roughname 其實不需要 parse regex，因為通常跟 imgname 是對應的，\n",
    "            # 我們假設 imgname 的 sort_num 就是這組資料的順序\n",
    "            \n",
    "            img_path = img_path.replace('\\\\', '/')\n",
    "            rough_path = rough_path.replace('\\\\', '/')\n",
    "            \n",
    "            # 使用 Regex 解析檔名\n",
    "            match = self.pattern.match(imgname)\n",
    "            \n",
    "            if match:\n",
    "                sort_num = int(match.group(1)) # 轉成 int 以便排序\n",
    "                group_key = match.group(2)     # 例如 \"HV011_FATFRACTION\"\n",
    "                \n",
    "                # 關鍵修改：將 Img, Rough, 和 原始Row 全部打包\n",
    "                groups[group_key].append((sort_num, img_path, rough_path, row))\n",
    "                \n",
    "                # print(f\"Parsed: {imgname} -> Key: {group_key}, Sort: {sort_num}\")\n",
    "            else:\n",
    "                print(f\"[Warning] Filename pattern mismatch: {imgname}\")\n",
    "\n",
    "        return groups\n",
    "\n",
    "    def process_groups(self, groups):\n",
    "        \"\"\"\n",
    "        執行拼接 (同時拼接 Image 和 Rough Label)\n",
    "        \"\"\"            \n",
    "        valid_pairs = 0\n",
    "        orphans = []\n",
    "        ambiguous = []\n",
    "        \n",
    "        # 用來收集拼接後的資料，傳給 update_csv 使用\n",
    "        # 結構: list of new rows (Series)\n",
    "        stitched_rows_data = [] \n",
    "\n",
    "        print(f\"\\n--- Starting Stitching Process ---\")\n",
    "\n",
    "        for key, items in groups.items():\n",
    "            count = len(items)\n",
    "            \n",
    "            if count == 2:\n",
    "                # === 完美配對 (Case A) ===\n",
    "                # items 是 list of (sort_num, img_path, rough_path, row)\n",
    "                # 根據 sort_num 排序: 小(Upper) -> 大(Lower)\n",
    "                items.sort(key=lambda x: x[0]) \n",
    "                \n",
    "                upper_item = items[0] \n",
    "                lower_item = items[1]\n",
    "                \n",
    "                # 1. 拼接 Image\n",
    "                success_img, output_img_name = self.stitch_pair(\n",
    "                    upper_item[1], lower_item[1], # img paths\n",
    "                    upper_item[0], key,           # sort_num, key\n",
    "                    is_label=False\n",
    "                )\n",
    "                \n",
    "                # 2. 拼接 Label (Order=0 Nearest Neighbor)\n",
    "                success_rough, output_rough_name = self.stitch_pair(\n",
    "                    upper_item[2], lower_item[2], # rough paths\n",
    "                    upper_item[0], key,           # sort_num, key\n",
    "                    is_label=True\n",
    "                )\n",
    "\n",
    "                if success_img and success_rough:\n",
    "                    valid_pairs += 1\n",
    "                    \n",
    "                    # === 準備更新 CSV 的資料 ===\n",
    "                    # 複製 Upper 的原始資料當作基底\n",
    "                    new_row = upper_item[3].copy()\n",
    "                    \n",
    "                    # 產生新的檔名 (需與 stitch_pair 中的存檔邏輯一致)\n",
    "                    # 邏輯: {Upper_Sort_Num}_full_{Key}.nii.gz\n",
    "                    new_filename = f\"{upper_item[0]}_full_{key}.nii.gz\"\n",
    "                    \n",
    "                    # 更新路徑 (存相對路徑或絕對路徑皆可，這裡示範存 output 資料夾下的路徑)\n",
    "                    new_row[IMAGE_3D_FILE] = output_img_name.replace('/', '\\\\')\n",
    "                    new_row[ROUGH_LABEL_3D_FILE] = output_rough_name.replace('/', '\\\\')\n",
    "                    \n",
    "                    stitched_rows_data.append(new_row)\n",
    "                    \n",
    "            elif count < 2:\n",
    "                orphans.append(key)\n",
    "            else:\n",
    "                ambiguous.append((key, count))\n",
    "\n",
    "        # --- Report ---\n",
    "        print(f\"\\nProcessed {valid_pairs} pairs successfully.\")\n",
    "        if orphans: \n",
    "            print(f\"[Warning] {len(orphans)} orphans found. -- non added to output folder.\")\n",
    "            for orphan in orphans:\n",
    "                print(f\"  - Orphan group: {orphan}\")\n",
    "        if ambiguous: \n",
    "            print(f\"[Warning] {len(ambiguous)} ambiguous groups found. -- none added to output folder.\")\n",
    "            for ambi in ambiguous:\n",
    "                print(f\"  - Ambiguous group: {ambi[0]} with {ambi[1]} items\")\n",
    "        \n",
    "        return stitched_rows_data\n",
    "\n",
    "    def stitch_pair(self, subpath_u, subpath_l, sort_num, group_key, is_label=False):\n",
    "        \"\"\"\n",
    "        通用拼接函式 (可處理 Image 或 Label)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            path_l = os.path.join(RAW_DATA_FOLDER, subpath_l)\n",
    "            path_u = os.path.join(RAW_DATA_FOLDER, subpath_u)\n",
    "            print(f\"subpath_u: {subpath_u}\")\n",
    "            if not os.path.exists(path_u) or not os.path.exists(path_l):\n",
    "                print(f\"[Error] File missing for {group_key} - {path_u} or {path_l} not found.\")\n",
    "                return False\n",
    "\n",
    "            img_u = nib.load(path_u)\n",
    "            img_l = nib.load(path_l)\n",
    "            data_u = img_u.get_fdata()\n",
    "            data_l = img_l.get_fdata()\n",
    "            \n",
    "            # Resize logic\n",
    "            if data_u.shape[:2] != data_l.shape[:2]:\n",
    "                target_h = min(data_u.shape[0], data_l.shape[0])\n",
    "                target_w = min(data_u.shape[1], data_l.shape[1])\n",
    "                # Label 用 order=0 (Nearest), Image 用 order=1 (Linear)\n",
    "                order = 0 if is_label else 1\n",
    "                data_u = resize_image(data_u, (target_h, target_w, data_u.shape[2]), order)\n",
    "                data_l = resize_image(data_l, (target_h, target_w, data_l.shape[2]), order)\n",
    "            \n",
    "            # 拼接\n",
    "            data_l = data_l[:, :, :-1]\n",
    "            data_u = data_u[:, :, 1:]\n",
    "            stitched_data = np.concatenate([data_l, data_u], axis=2)\n",
    "            \n",
    "            # 存檔\n",
    "            new_img = nib.Nifti1Image(stitched_data, img_u.affine, img_u.header)\n",
    "            save_name = f\"{sort_num}_{group_key}.nii.gz\"\n",
    "            output_name = os.path.join(os.path.dirname(subpath_l), save_name)\n",
    "            save_path = os.path.join(FIXED_DATA_ROOT, output_name)\n",
    "            nib.save(new_img, save_path)\n",
    "            print(f\"[Info] Stitched saved: {save_path}\")\n",
    "            \n",
    "            return True, output_name\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] Stitching failed for {group_key}: {e}\")\n",
    "            return False, None\n",
    "\n",
    "def resize_image(image, target_shape, order=1):\n",
    "    current_shape = image.shape\n",
    "    zoom_factors = [\n",
    "        target_shape[0] / current_shape[0],\n",
    "        target_shape[1] / current_shape[1],\n",
    "        target_shape[2] / current_shape[2]\n",
    "    ]\n",
    "    return zoom(image, zoom_factors, order=order)\n",
    "\n",
    "def update_csv_direct(original_csv_path, output_csv_path, new_rows_list):\n",
    "    \"\"\"\n",
    "    直接接收處理好的 new_rows_list 並寫入新的 CSV\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Generating Updated CSV: {output_csv_path} ---\")\n",
    "    \n",
    "    # 1. 讀取原始 CSV (為了保留那些 \"不需要拼接\" 的資料，例如其他 Dataset 的資料)\n",
    "    df = pd.read_csv(original_csv_path)\n",
    "    \n",
    "    # 2. 移除舊的 \"MyoSegmenTUM + Control\" 資料\n",
    "    # 我們要用新生成的 stitched rows 來取代它們\n",
    "    # 條件: Dataset不是MyoSegmenTUM 或者 Phenotype不是Control 的資料要保留\n",
    "    df_kept = df[~(df[DATASET] == TARGET_DATASET)]\n",
    "    \n",
    "    # 3. 建立新資料的 DataFrame\n",
    "    if new_rows_list:\n",
    "        df_new = pd.DataFrame(new_rows_list)\n",
    "        \n",
    "        # 4. 合併 (保留的舊資料 + 拼接後的新資料)\n",
    "        df_final = pd.concat([df_kept, df_new], ignore_index=True)\n",
    "        \n",
    "        # 5. 存檔\n",
    "        df_final.to_csv(output_csv_path, index=False)\n",
    "        print(f\"Success! Updated CSV saved with {len(df_final)} rows.\")\n",
    "    else:\n",
    "        print(\"No new stitched rows to update. CSV remains unchanged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89443a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定路徑\n",
    "if not os.path.exists(RAW_CSV_FILE):\n",
    "    print(\"CSV file not found.\")\n",
    "    exit()\n",
    "\n",
    "stitcher = CsvThighStitcher(RAW_CSV_FILE)\n",
    "\n",
    "# 1. Parse & Group (只跑一次，同時包含 Img 和 Rough 的資訊)\n",
    "grouped_data = stitcher.parse_csv_and_group(RAW_DATA_FOLDER)\n",
    "\n",
    "# 2. Process & Stitch (回傳可以用來寫入 CSV 的 rows)\n",
    "stitched_rows = stitcher.process_groups(grouped_data)\n",
    "\n",
    "# 3. Update CSV (直接拿上面的結果來存，不用再 parse 一次)\n",
    "update_csv_direct(RAW_CSV_FILE, OUTPUT_CSV_FILE, stitched_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936d94b",
   "metadata": {},
   "source": [
    "### 6. convert 3D to 2D & add position, measure_type embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fff298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_id(sequence_name):\n",
    "    \"\"\"將文字類別轉為整數 ID\"\"\"\n",
    "    # 移除可能的空白並轉 Title case (e.g., \" water \" -> \"Water\")\n",
    "    clean_name = str(sequence_name).strip()\n",
    "    # 模糊比對或直接查表\n",
    "    for key, val in TYPE_MAP.items():\n",
    "        if key.upper() in clean_name.upper():\n",
    "            return val\n",
    "    return -1 # 未知類別\n",
    "\n",
    "# ==========================================\n",
    "# 2. 執行切片與 Embedding 注入\n",
    "# ==========================================\n",
    "print(f\"Reading CSV: {OUTPUT_CSV_FILE}\")\n",
    "df = pd.read_csv(OUTPUT_CSV_FILE)\n",
    "print(f\"Total subjects to process: {len(df)}\")\n",
    "fail_files = []\n",
    "success_count = 0\n",
    "fail_count = 0\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Slicing 3D Volumes\"):\n",
    "    # 1. 取得路徑 (修正 Windows/Linux 分隔符號)\n",
    "    sub_img_path = str(row[IMAGE_3D_FILE]).replace('\\\\', '/')\n",
    "    sub_rough_lbl_path = str(row[ROUGH_LABEL_3D_FILE]).replace('\\\\', '/')\n",
    "    sub_detail_lbl_path = str(row[DETAILED_LABEL_3D_FILE]).replace('\\\\', '/')\n",
    "    img_path = os.path.join(FIXED_DATA_ROOT, sub_img_path) \n",
    "    rough_lbl_path = os.path.join(FIXED_DATA_ROOT, sub_rough_lbl_path)\n",
    "    \n",
    "    has_detail = False\n",
    "    detail_path = None\n",
    "    detail_lbl_path = os.path.join(FIXED_DATA_ROOT, sub_detail_lbl_path)\n",
    "    print(f\"detail_lbl_path: {detail_lbl_path}\")\n",
    "    if os.path.exists(detail_lbl_path):\n",
    "        has_detail = True\n",
    "    \n",
    "    # 取得 MRI 序列類別\n",
    "    seq_name = row.get(MRI_SEQUENCE) # 假如 CSV 有這欄\n",
    "    type_idx = get_type_id(seq_name)\n",
    "    MRI_sample = row.get(MRI_SAMPLRE, \"\")\n",
    "    \n",
    "    print(f\"MRI_sample: {MRI_sample}\")\n",
    "    \n",
    "    try:\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"File not found: {img_path}\")\n",
    "\n",
    "        # 2. 讀取 NIfTI\n",
    "        img_obj = nib.load(img_path)\n",
    "        rough_lbl_obj = nib.load(rough_lbl_path)\n",
    "        detail_lbl_obj = nib.load(detail_lbl_path) if has_detail else None\n",
    "        \n",
    "        # 轉為 Numpy Array (H, W, D)\n",
    "        img_vol = img_obj.get_fdata()\n",
    "        rough_lbl_vol = rough_lbl_obj.get_fdata()\n",
    "        detail_lbl_vol = detail_lbl_obj.get_fdata() if has_detail else np.zeros_like(rough_lbl_vol)\n",
    "        \n",
    "        vol_max = np.max(img_vol)\n",
    "        \n",
    "        # 3. 獲取維度資訊\n",
    "        h, w, d = img_vol.shape\n",
    "        filename = os.path.basename(img_path)\n",
    "        \n",
    "        # 4. 開始切片 (Slice along Z-axis)\n",
    "        for z in range(d):\n",
    "            # --- A. 提取資料 ---\n",
    "            slice_img = img_vol[:, :, z]\n",
    "            slice_rough_lbl = rough_lbl_vol[:, :, z]\n",
    "            slice_detail_lbl = detail_lbl_vol[:, :, z]\n",
    "            \n",
    "            # 刪掉屁股附近全黑的切片\n",
    "            if np.max(slice_rough_lbl) == 0:\n",
    "                print(f\"[Info] Skipping slice {z} of {filename} due to empty rough label.\")\n",
    "                # 跳過全黑標註或有 NaN 的切片\n",
    "                continue\n",
    "            \n",
    "            slice_img = np.rot90(slice_img, k=-1)\n",
    "            slice_rough_lbl = np.rot90(slice_rough_lbl, k=-1)\n",
    "            slice_detail_lbl = np.rot90(slice_detail_lbl, k=-1)\n",
    "            \n",
    "            new_h, new_w = slice_img.shape\n",
    "            \n",
    "            # --- B. 數值正規化 (Normalization) ---\n",
    "            # 雖然不改大小，但數值建議先縮放到 0-1，避免存成 float32 時數值過大\n",
    "            if vol_max > 0:\n",
    "                slice_img = slice_img / vol_max\n",
    "            \n",
    "            # --- C. 計算 Embedding ---\n",
    "            # Position Embedding: 相對位置 (0.0 ~ 1.0)\n",
    "            z_pos = 1.0 - (z / (d - 1)) if d > 1 else 0.0\n",
    "            # z_pos = 1-z_pos  # 反轉位置，0.0 = 屁股, 1.0 = 膝蓋\n",
    "            \n",
    "            \n",
    "            # 每位病患的每個 slice 為一個 npy 檔案，包含不同量測的 image 與 一個 label\n",
    "            save_data = {\n",
    "                \"image_Water\": slice_img.astype(np.float32),       # (H, W) 原尺寸\n",
    "                \"image_Fat\": slice_img.astype(np.float32),         # (H, W) 原尺寸\n",
    "                \"image_T1\": slice_img.astype(np.float32),          # (H, W) 原尺寸\n",
    "                \"image_T2\": slice_img.astype(np.float32),          # (H, W) 原尺寸\n",
    "                \"image_STIR\": slice_img.astype(np.float32),        # (H, W) 原尺寸\n",
    "                \"image_FATFRACTION\": slice_img.astype(np.float32), # (H, W) 原尺寸\n",
    "                \"rough_label\": slice_rough_lbl.astype(np.uint8),    \n",
    "                \"detail_label\": slice_detail_lbl.astype(np.uint8), \n",
    "                \"has_detail\": np.bool_(has_detail),                # 是否有詳細標註\n",
    "                \"z_pos\": np.float32(z_pos),                        # \n",
    "                \"this_slice\": int(z+1),                            # 純量\n",
    "                \"total_slices\": int(d),                            # 純量\n",
    "            }\n",
    "            \n",
    "            # --- E. 存檔 (.npy) ---\n",
    "            # 檔名範例: 533_1_HV014_FAT.npy\n",
    "            # file_name = os.path.splitext(filename)[0].split('_')\n",
    "            slice_name = os.path.splitext(filename)[0].split('.')[0].split('_')            \n",
    "            save_name = f\"{slice_name[0]}_{type_idx}_{'_'.join(slice_name[1:])}_slice{z:03d}.npy\"\n",
    "            save_path = os.path.join(OUTPUT_SLICE_DIR, sub_img_path.split('/')[-3], str(save_name))\n",
    "            print(f\"[Info] Saved slice: {save_path}\")\n",
    "            \n",
    "            np.save(save_path, save_data)\n",
    "            \n",
    "        success_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed {img_path}: {e}\")\n",
    "        fail_files.append(img_path)\n",
    "        fail_count += 1\n",
    "\n",
    "print(f\"\\nProcessing Done!\")\n",
    "print(f\"Success Volumes: {success_count}\")\n",
    "print(f\"Failed Volumes : {fail_count}\")\n",
    "print(f\"Failed Files  : {fail_files}\")\n",
    "print(f\"Saved to: {OUTPUT_SLICE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a111e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定你的 .npy 資料夾 (請確認路徑是否正確，例如是否在 train/image 底下)\n",
    "npy_dir = os.path.join(OUTPUT_SLICE_DIR,'train')\n",
    "\n",
    "cmap_rough = mcolors.ListedColormap(POSITION_ROUGH_EMBEDDING_COLORS)\n",
    "cmap_detailed = mcolors.ListedColormap(POSITION_DETAILED_EMBEDDING_COLORS)\n",
    "\n",
    "\n",
    "# 1. 搜尋檔案\n",
    "files = glob.glob(os.path.join(npy_dir, \"*.npy\"))\n",
    "print(f\"Found {len(files)} .npy slices.\")\n",
    "\n",
    "if len(files) == 0:\n",
    "    print(\"Error: No files found. Check your directory path.\")\n",
    "else:\n",
    "    # 2. 隨機抽樣 3 張來檢查\n",
    "    samples = random.sample(files, 10)\n",
    "\n",
    "    for i, fpath in enumerate(samples):\n",
    "        print(f\"\\n\" + \"=\"*50)\n",
    "        print(f\"Checking Sample {i+1}: {os.path.basename(fpath)}\")\n",
    "        \n",
    "        # 讀取\n",
    "        data = np.load(fpath, allow_pickle=True).item()\n",
    "        \n",
    "        # 提取資料 (注意 Key 名稱需對應存檔時的設定)\n",
    "        img = data['image']\n",
    "        lbl_rough = data.get('rough_label')   # 粗標註\n",
    "        lbl_detail = data.get('detail_label') # 細標註\n",
    "        has_detail = data.get('has_detail', False)\n",
    "        z_pos = data.get('z_pos', -1)\n",
    "        type_idx = data.get('type_idx', -1)\n",
    "        MRI_sample = data.get('MRI_sample', 'Unknown')\n",
    "        this_slice = data.get('this_slice', -1)\n",
    "        total_slices = data.get('total_slices', -1)\n",
    "        print(f\"- z_pos: {z_pos:.4f}, type_idx: {type_idx}, has_detail: {has_detail}, MRI sample: {MRI_sample}, Slice: {this_slice}/{total_slices}\")\n",
    "        \n",
    "        # --- 建立畫布 (1列 3行) ---\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # 共用的顯示設定\n",
    "        title_fontsize = 12\n",
    "        \n",
    "        # === Plot 1: 原圖 (Raw Image) ===\n",
    "        axes[0].imshow(img, cmap='gray')\n",
    "        axes[0].set_title(f\"Raw Image\\nType: {type_idx}, Z: {z_pos:.2f}\", fontsize=title_fontsize)\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # === Plot 2: 原圖 + Rough Label (Overlay) ===\n",
    "        axes[1].imshow(img, cmap='gray') # 先畫底圖\n",
    "        if lbl_rough is not None:\n",
    "            # 將背景 (0) 遮罩起來，使其完全透明\n",
    "            masked_rough = ma.masked_where(lbl_rough == 0, lbl_rough)\n",
    "            # 疊加 Label (alpha=0.5 半透明, cmap='tab10' 顏色對比高)\n",
    "            axes[1].imshow(masked_rough, cmap=cmap_rough, alpha=0.5, interpolation='nearest')\n",
    "            axes[1].set_title(f\"Overlay: Rough Label\\n(5 Classes)\", fontsize=title_fontsize)\n",
    "        else:\n",
    "            axes[1].text(0.5, 0.5, \"No Rough Label\", ha='center', color='red')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        # === Plot 3: 原圖 + Detailed Label (Overlay) ===\n",
    "        axes[2].imshow(img, cmap='gray') # 先畫底圖\n",
    "        if has_detail and lbl_detail is not None:\n",
    "            # 將背景 (0) 遮罩起來\n",
    "            masked_detail = ma.masked_where(lbl_detail == 0, lbl_detail)\n",
    "            # 疊加 Label (使用 tab20 以區分更多類別)\n",
    "            axes[2].imshow(masked_detail, cmap=cmap_detailed, alpha=0.6, interpolation='nearest')\n",
    "            axes[2].set_title(f\"Overlay: Detailed Label\\n(12 Classes)\", fontsize=title_fontsize)\n",
    "        else:\n",
    "            # 如果這張圖本身就沒有 Detail Label (例如只有 Rough 的資料)\n",
    "            axes[2].text(0.5, 0.5, \"No Detailed Label\\n(Source Missing)\", ha='center', va='center', color='yellow', fontsize=14, backgroundcolor='black')\n",
    "            axes[2].set_title(\"Overlay: Detailed Label\", fontsize=title_fontsize)\n",
    "        axes[2].axis('off')\n",
    "        \n",
    "        detailed_patches = [mpatches.Patch(color=POSITION_DETAILED_EMBEDDING_COLORS[i], label=f\"{i}: {DETAIL_MUSCLE_NAMES[i]}\") \n",
    "                   for i in DETAIL_MUSCLE_NAMES.keys() if i > 0] # 不顯示背景\n",
    "        rough_patches = [mpatches.Patch(color=POSITION_ROUGH_EMBEDDING_COLORS[i], label=f\"{i}: {ROUGH_MUSCLE_NAMES[i]}\") \n",
    "                   for i in ROUGH_MUSCLE_NAMES.keys() if i > 0] #\n",
    "        \n",
    "        # 將圖例放在最右邊\n",
    "        fig.legend(handles=detailed_patches + rough_patches, loc='center right', bbox_to_anchor=(1.1, 0.5), title=\"Muscle Classes\")\n",
    "    \n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
